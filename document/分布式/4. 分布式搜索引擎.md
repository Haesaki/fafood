# 分布式搜索引擎

## 搜索引擎

### 是什么

- 优化搜索体验
- 根据用户提供贴合用户请求的的搜索体验
- 分布式存储和搜索

### 功能

1. 支持空格分隔关键词
2. 拆词查询
3. 搜素结果高亮不能显示 在google搜索词语 会在网页的下方显示出关键词
4. 海量的数据查库 搜索并发很多 数据库存在崩溃的情况

### 常见的开源引擎

**Lucene**

- 倒排序索引
- Lucene是类库

**Solr** 基于lucene

**Elasticsearrch** 基于lucene

- 支持pb级别的查询
- 现代风格
- 出现时间晚
- 分布式
- 简化了数据采集 可视化 和报告过程

## ElasticSearch

### 术语

- 索引 index          表
- 类型 type            表的逻辑类型   区分索引 最新版本已经取消了type这个
- 文档 document   行
- 字段 fields          列

### 核心概念

- 映射 mapping   表结构定义
- Near real time
- 节点 node        每一个节点是一个服务器
- shard replica   数据分片和备份

### 集群构架

多节点

<img src="Untitled.assets/image-20220422153859059.png" alt="image-20220422153859059" style="zoom:50%;" />

### 倒排索引

根据几个word去查询

| 文档id |       内容       |
| :----: | :--------------: |
|   1    | 菜鸟教程值得学习 |
|   2    |  菜鸟教程是网站  |
|   3    | 菜鸟教程学习视频 |

| 单词 | 文档dis | 词频:位置 |
| :--: | :-----: | :-------: |
| 菜鸟 |  1 2 3  |  1:1:<1>  |
| 教程 |  1 2 3  |           |
| 值得 |    1    |           |
| 学习 |   1 3   |           |
|  是  |    1    |           |
|  站  |    2    |           |
| 视频 |    3    |           |

倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)。带有倒排索引的文件我们称为倒排[索引文件](https://baike.baidu.com/item/索引文件)，简称[倒排文件](https://baike.baidu.com/item/倒排文件/4137688)(inverted file)。



### 安装

[Install](https://www.elastic.co/guide/en/elasticsearch/reference/current/targz.html) 

注意最新版的spring-boot-elasticsearch-starter中的客户端是 7.15.2 （不知道服务端要不要和客户端版本相同， 这个版本启动elasticsearch 不会自动启动security manager）

```shell
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.3-linux-x86_64.tar.gz
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.1.3-linux-x86_64.tar.gz.sha512
shasum -a 512 -c elasticsearch-8.1.3-linux-x86_64.tar.gz.sha512 
tar -xzf elasticsearch-8.1.3-linux-x86_64.tar.gz
cd elasticsearch-8.1.3/ 
# 修改 config/elasticsearch.yml 文件后
# 需要创建一个用户 将 elasticsearch-8.1.3/ 所有者转移给你创建的用户
chown -R es:es /usr/local/elasticsearch-8.1.3
# 需要修改config下面elasticsearch.yml  jvm.options
# 第二个主要是调整最大支持的jvm内存空间大小
# 修改 
cluster.name: fafood
node.name: node-1
path.data: /elasticsearch/data
path.logs: /elasticsearch/log
network.host: 0.0.0.0
cluster.initial_master_nodes: ["node-1"]
# 报了一个错 关于es用户的 可以修改 es user的配置
# [2] bootstrap checks failed. You must address the points described in the following [2] lines before starting Elasticsearch.
# bootstrap check failure [1] of [2]: max number of threads [3771] for user [es] is too low, increase to at least [4096]
# bootstrap check failure [2] of [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
vim /etc/security/limits.conf
# 最后添加这些
* soft nofile 65536
* hard nofile 131072
* soft nproc 2048
* hard nproc 4096
vim /etc/sysctl.conf
vm.max_map_count=262145
# 切换到对应的es用户 然后 再后台运行就行了 不能再root用户下运行， 主要是安全问题
./elasticsearch -d # 后台运行

# 默认开启认证以及加密的功能
# 最新版会默认开启安全管理功能
# 7.15.6 不会开启这个功能
✅ Elasticsearch security features have been automatically configured!
✅ Authentication is enabled and cluster connections are encrypted.

ℹ️  Password for the elastic user (reset with `bin/elasticsearch-reset-password -u elastic`):
  +SZfO0Ar58X7N_rOdhT*

ℹ️  HTTP CA certificate SHA-256 fingerprint:
  7215d2d8732a23991ca55579525f59245ca43f948b00f57b4a1a7c541f2d2890

ℹ️  Configure Kibana to use this cluster:
• Run Kibana and click the configuration link in the terminal when Kibana starts.
• Copy the following enrollment token and paste it into Kibana in your browser (valid for the next 30 minutes):
  eyJ2ZXIiOiI4LjEuMiIsImFkciI6WyIxNTkuMjIzLjcwLjE3Nzo5MjAwIl0sImZnciI6IjcyMTVkMmQ4NzMyYTIzOTkxY2E1NTU3OTUyNWY1OTI0NWNhNDNmOTQ4YjAwZjU3YjRhMWE3YzU0MWYyZDI4OTAiLCJrZXkiOiJjSldCVVlBQnM4ZjVJb3ZCM080Mzo4SXJHamJHdlR3T2VhYUZrd3JpTGNRIn0=

ℹ️ Configure other nodes to join this cluster:
• Copy the following enrollment token and start new Elasticsearch nodes with `bin/elasticsearch --enrollment-token <token>` (valid for the next 30 minutes):
  eyJ2ZXIiOiI4LjEuMiIsImFkciI6WyIxNTkuMjIzLjcwLjE3Nzo5MjAwIl0sImZnciI6IjcyMTVkMmQ4NzMyYTIzOTkxY2E1NTU3OTUyNWY1OTI0NWNhNDNmOTQ4YjAwZjU3YjRhMWE3YzU0MWYyZDI4OTAiLCJrZXkiOiJjcFdCVVlBQnM4ZjVJb3ZCM081UjpEZlp0RHhrSlQ4SzRGZl9icF9xdGdRIn0=

  If you're running in Docker, copy the enrollment token and run:
  `docker run -e "ENROLLMENT_TOKEN=<token>" docker.elastic.co/elasticsearch/elasticsearch:8.1.2`
```

可以通过默认的9200 端口访问 elasticsearch 9300 端口是默认内网访问地址

### 安装出现的问题

1. 无法访问9200端口

```log
    [WARN ][o.e.x.s.t.n.SecurityNetty4HttpServerTransport] [node-1] received plaintext http traffic on an https channel, closing connection Netty4HttpChannel{localAddress=/localhost:9200, remoteAddress=/localhost:9200
```

这是由于开启了安全措施导致无法访问，关闭ssl以及security就成

```yaml
xpack.security.enabled: false
xpack.security.enrollment.enabled: false
# Enable encryption for HTTP API client connections, such as Kibana, Logstash, and Agents
xpack.security.http.ssl:
  enabled: false
# Enable encryption and mutual authentication between cluster nodes
xpack.security.transport.ssl:
  enabled: false
```

相应信息中重要的是status字段

- green：主 副副本都已经分配了，集群100%可用
- yellow：所有主分片已经分片了，至少一个副本是缺失的没有数据丢失 需要即使调查的警告
- red：至少一个主分在缺失中，缺少数据，搜索只能返回部分数据，分配到这个分派你的写入请求会放回异常

## 数据结构

其实这些数据结构都是在某个索引下面进行的操作

### Mapping

#### 创建mapping

```json
// put http://159.223.70.177:9200/index_mapping
// 向名为index_mapping的索引添加新的mapping
{
    "mappings":{
        "properties":{
            "realname":{
                "type": "text", // 想分词可以使用text
                "index": true
            },
            "username":{
                "type": "keyword", // 不会被分词 只能精确匹配
                "index": false
            }
        }
    }
}
// return
{
	"acknowledged": true,
	"shards_acknowledged": true,
	"index": "index_mapping"
}
// 验证 get http://159.223.70.177:9200/index_mapping/_analyze
{
    "field": "realname",
    "text": "sin is good"
}
// 会得到分词过后的内容
{
	"tokens": [
		{
			"token": "sin",
			"start_offset": 0,
			"end_offset": 3,
			"type": "<ALPHANUM>",
			"position": 0
		}, ..... 
}

// 修改 索引 不能修改 要修改只能删除 然后再添加
// 只能增加额外内容
{
    "properties":{
        "id":{
            "type":"long"
        }
    }
}
```

主要数据类型

- text， keyword
- long， integer， short，byte
- double， float
- boolean
- date
- object

### 文档

```json
// my_doc是我新建的index
// 新建新的文档 post http://159.223.70.177:9200/my_doc/doc/1 行号为1 插入数据
{
    "id":1001,
    "name":"sin1",
    "desc":"sin sin sin",
    "create_date":"2019-1-1"
}
// 删除delete http://159.223.70.177:9200/my_doc/_doc/5
// 增加 put http://159.223.70.177:9200/my_doc/_doc/5
{
    "doc"{
    	"id":1,
    	"name": "update-imooc",
    	"desc": "慕课网牛逼",
    	"create_date": "2019-12-24"
	}
}
// 向名为index_mapping的索引添加新的mapping
```

### IK analysis of elasticsearch 中文分词器

```json
// post http://localhost:9200/_analyze
{
	"analyzer": "ik_max_word", // "ik_max_word" 会做最细粒度的拆分, "ik_smart"
    "text": "上下班好几把挤啊"
}
```

IKAnalyzer.cfg.xml` can be located at `{conf}/analysis-ik/config/IKAnalyzer.cfg.xml` or `{plugins}/elasticsearch-analysis-ik-*/config/IKAnalyzer.cfg.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
	<comment>IK Analyzer 扩展配置</comment>
	<!--用户可以在这里配置自己的扩展字典 -->
	<entry key="ext_dict">custom/mydict.dic;custom/single_word_low_freq.dic</entry>
	 <!--用户可以在这里配置自己的扩展停止词字典-->
	<entry key="ext_stopwords">custom/ext_stopword.dic</entry>
 	<!--用户可以在这里配置远程扩展字典 -->
	<entry key="remote_ext_dict">location</entry>
 	<!--用户可以在这里配置远程扩展停止词字典-->
	<entry key="remote_ext_stopwords">http://xxx.com/xxx.dic</entry>
</properties>
```

## DSL

新建一个index 例如 fafoodshop

```json
// post http://localhost:9200/fafoodshop/_mapping
{
    "proerties":{
        "id":{
            "type": "long"
        },
        "age":{
            "type": "integer"
        },
        "username":{
            "type":"keyword"
        },
        "nickname":{
            "type":"text",
            "analyzer": "ik_max_word"
        },
        "desc":{
            "type":"text",
            "analyzer": "ik_max_word"
        },"money":{
            "type":"float"
        },"sex":{
            "type":"byte"
        },"birthady":{
            "type":"date"
        },"face":{
            "type":"text",
            "index":false
        }
    }
}
// 查询 post http://localhost:9200/fafoodshop/_doc/_search
{
    "query":{
        "exists":{
            "desc":"username1"
        }
    }
}
// select * from shop
{
    "query":{
        "match_all":{
            "desc":"username1"
        }
    }
}
// select id, nickname, age form shop
{
    "query":{
        "match_all":{}
    },
    "source":[
        "id",
        "nickname",
        "age"
    ],
    // index从0开始 每页大小为10
    "from": 0,
    "size": 10
}
```

自己测试

```json
// 插入数据 http://159.223.70.177:9200/testes/_doc/1 (id 1)
// 如果没有指定id elasticsearch 默认帮你指定一个id
{
    "name":"hasaki",
    "nickname":"hasaki hasaki",
    "desc": "hasaki is good people"
}
// 创建mapping http://159.223.70.177:9200/testes
{
    "mappings":{
        "properties":{
            "name":{
                "type":"text",
                "index":"true"
            },
            "nickname":{
                "type":"text"
            },
            "desc":{
                "type":"text"
            }
        }
    }
}
// DELETE  http://192.168.1.11:9200/index_user/_doc/1 删除文档
// POST  http://192.168.1.11:9200/index_user/_doc/1/_update 修改部分数据
// PUT http://192.168.1.11:9200/index_user/_doc/1 替换id为1的全部内容
// GET  http://192.168.1.11:9200/index_user/_doc/1 根据ID查询文档
// GET  http://192.168.1.11:9200/index_user/_doc/_search 查询所有文档
// GET  http://192.168.1.11:9200/index_user/_doc/1?_source=name,age 自定义
// GET  http://192.168.1.11:9200/index_user/_doc/_search?_source=name,age
// get http://159.223.70.177:9200/_cluster/health 健康状态
// get http://159.223.70.177:9200/_cat/health?v 健康状态
```



### 故障测试

#### 集群节点宕机测试

master节点挂了，会有一个节点被选举成master，当原master恢复后 并不会恢复成master 而是变成node节点 。

数据会进行同步 主分片和副分片

#### 集群脑裂现象

网络中断 网络异常 节点宕机 会导致一个集群分裂成具有两个master的集群。之前版本通过设置最小投票人数 可以限制脑裂情况。现在版本已经通过自动配置去除了这个问题。

### 集群的文档读写原理

用户请求直接转发奥coordinating node 协调节点 然后再会转发到主分片或者福分片轮询读取操作。

服务器端和客户端的需要相同么？ 服务器端是8.1.12 客户端是7.15.2

```properties
spring.data.elasticsearch.cluster-name = a
spring.data.elasticsearch.cluster-nodes = a    被废弃了
转而使用elsaticjava代码配置
```

## Logstash

数据库和elasticsearch进行同步操作
